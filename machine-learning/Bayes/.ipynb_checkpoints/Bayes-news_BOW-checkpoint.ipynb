{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "20\n",
      "18846\n",
      "18846\n"
     ]
    }
   ],
   "source": [
    "news = fetch_20newsgroups(subset=\"all\")\n",
    "print(news.target_names)# 新闻的种类标签 20 \n",
    "print(len(news.target_names))# 20\n",
    "print(len(news.data)) # datas 18846\n",
    "print(len(news.target))# 18846 tabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain = fetch_20newsgroups(subset = \"train\")\\nx_train = train.data\\ny_train = train.target\\ntest = fetch_20newsgroup(subset =\"test\")\\nx_test = text_data\\ny_test = text.target\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slice data \n",
    "x_train, x_test, y_train, y_test = train_test_split(news.data, news.target)\n",
    "\"\"\"\n",
    "train = fetch_20newsgroups(subset = \"train\")\n",
    "x_train = train.data\n",
    "y_train = train.target\n",
    "test = fetch_20newsgroup(subset =\"test\")\n",
    "x_test = text_data\n",
    "y_test = text.target\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['also', 'football', 'games', 'john', 'likes', 'mary', 'movies', 'to', 'too', 'watch']\n",
      "[[0 0 0 1 2 1 1 1 1 1]\n",
      " [1 1 1 1 1 0 0 1 0 1]]\n",
      "[1 1 1 2 3 1 1 2 1 2]\n"
     ]
    }
   ],
   "source": [
    "# 构建Word dictionary\n",
    "tests = [\"john likes to watch movies mary likes too\",\n",
    "         \"john also likes to watch football games\"]\n",
    "cv = CountVectorizer()\n",
    "cv_fit = cv.fit_transform(tests)\n",
    "print(cv.get_feature_names())\n",
    "print(cv_fit.toarray())\n",
    "print (cv_fit.toarray().sum(axis=0)) # 这里对结果列表进行了纵向求和 得出文档中每个单词一共出现的次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'john': 3, 'likes': 4, 'to': 7, 'watch': 9, 'movies': 6, 'mary': 5, 'too': 8, 'also': 0, 'football': 1, 'games': 2}\n",
      "[1.40546511 1.40546511 1.40546511 1.         1.         1.40546511\n",
      " 1.40546511 1.         1.40546511 1.        ]\n",
      "(1, 10)\n",
      "[[0.         0.         0.         0.2781429  0.55628581 0.39092014\n",
      "  0.39092014 0.2781429  0.39092014 0.2781429 ]]\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF algorithm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tests = [\"john likes to watch movies mary likes too\",\n",
    "         \"john also likes to watch football games\"]\n",
    "# building transfrom func\n",
    "vectorizer = TfidfVectorizer()\n",
    "# 词条化以及创建词汇表\n",
    "vectorizer.fit(tests)\n",
    "print(vectorizer.vocabulary_)\n",
    "print(vectorizer.idf_)\n",
    "# 编码文档 \n",
    "vector = vectorizer.transform([tests[0]])\n",
    "print(vector.shape)\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
